# GitLab CI/CD Pipeline for Budget App - GCP Cloud Run Deployment
# Optimized for low costs

variables:
  # GCP Configuration
  GCP_PROJECT_ID: "budget-app-prod"
  GCP_REGION: "us-central1"
  CLOUD_RUN_SERVICE: "budget-app"
  
  # Container Registry (use Artifact Registry for better performance)
  IMAGE_NAME: "${GCP_REGION}-docker.pkg.dev/${GCP_PROJECT_ID}/budget-app/app"
  
  # Database
  CLOUD_SQL_INSTANCE: "budget-db"
  DB_NAME: "budgetapp"
  
  # Docker settings
  DOCKER_DRIVER: overlay2
  DOCKER_TLS_CERTDIR: "/certs"

# Define stages
stages:
  - test
  - build
  - deploy
  - post-deploy

# Cache configuration to speed up builds
cache:
  key: ${CI_COMMIT_REF_SLUG}
  paths:
    - node_modules/
    - .next/cache/

# Run tests and linting (only on merge requests and main branch)
test:
  stage: test
  image: node:18-alpine
  only:
    - merge_requests
    - main
  script:
    - echo "Installing dependencies..."
    - npm ci --prefer-offline --no-audit
    - echo "Running linter..."
    - npm run lint || echo "Lint check completed with warnings"
    - echo "Running type check..."
    - npm run build
  artifacts:
    expire_in: 1 hour
    paths:
      - .next/
      - node_modules/

# Build Docker image and push to Artifact Registry
build:
  stage: build
  image: google/cloud-sdk:alpine
  services:
    - docker:24-dind
  only:
    - main
    - tags
  before_script:
    # Authenticate with GCP using service account key
    - echo $GCP_SERVICE_KEY | base64 -d > ${HOME}/gcp-key.json
    - gcloud auth activate-service-account --key-file ${HOME}/gcp-key.json
    - gcloud config set project $GCP_PROJECT_ID
    
    # Configure Docker to use Artifact Registry
    - gcloud auth configure-docker ${GCP_REGION}-docker.pkg.dev --quiet
  script:
    # Build Docker image with commit SHA tag
    - echo "Building Docker image..."
    - docker build 
        --tag ${IMAGE_NAME}:${CI_COMMIT_SHORT_SHA}
        --tag ${IMAGE_NAME}:latest
        --build-arg BUILDKIT_INLINE_CACHE=1
        --cache-from ${IMAGE_NAME}:latest
        .
    
    # Push images
    - echo "Pushing image to Artifact Registry..."
    - docker push ${IMAGE_NAME}:${CI_COMMIT_SHORT_SHA}
    - docker push ${IMAGE_NAME}:latest
    
    - echo "Build completed! Image: ${IMAGE_NAME}:${CI_COMMIT_SHORT_SHA}"

# Deploy to Cloud Run
deploy:production:
  stage: deploy
  image: google/cloud-sdk:alpine
  only:
    - main
  environment:
    name: production
    url: https://${CLOUD_RUN_SERVICE}-${CI_COMMIT_SHORT_SHA}.run.app
  before_script:
    - echo $GCP_SERVICE_KEY | base64 -d > ${HOME}/gcp-key.json
    - gcloud auth activate-service-account --key-file ${HOME}/gcp-key.json
    - gcloud config set project $GCP_PROJECT_ID
  script:
    # Get Cloud SQL connection name
    - export CONNECTION_NAME=$(gcloud sql instances describe ${CLOUD_SQL_INSTANCE} --format='value(connectionName)')
    
    # Deploy to Cloud Run with cost-optimized settings
    - |
      gcloud run deploy ${CLOUD_RUN_SERVICE} \
        --image ${IMAGE_NAME}:${CI_COMMIT_SHORT_SHA} \
        --platform managed \
        --region ${GCP_REGION} \
        --allow-unauthenticated \
        --set-env-vars "NODE_ENV=production" \
        --set-secrets "DATABASE_URL=db-url:latest,NEXTAUTH_SECRET=nextauth-secret:latest" \
        --add-cloudsql-instances ${CONNECTION_NAME} \
        --vpc-connector budget-connector \
        --vpc-egress private-ranges-only \
        --min-instances 0 \
        --max-instances 5 \
        --memory 512Mi \
        --cpu 1 \
        --timeout 300 \
        --concurrency 80 \
        --cpu-throttling \
        --port 8080 \
        --quiet
    
    # Get service URL
    - export SERVICE_URL=$(gcloud run services describe ${CLOUD_RUN_SERVICE} --region ${GCP_REGION} --format='value(status.url)')
    - echo "Deployment successful!"
    - echo "Service URL: ${SERVICE_URL}"
  after_script:
    - rm -f ${HOME}/gcp-key.json

# Run database migrations after deployment
migrate:
  stage: post-deploy
  image: google/cloud-sdk:alpine
  only:
    - main
  needs:
    - deploy:production
  before_script:
    - echo $GCP_SERVICE_KEY | base64 -d > ${HOME}/gcp-key.json
    - gcloud auth activate-service-account --key-file ${HOME}/gcp-key.json
    - gcloud config set project $GCP_PROJECT_ID
    
    # Install Cloud SQL Proxy
    - wget https://storage.googleapis.com/cloud-sql-connectors/cloud-sql-proxy/v2.8.2/cloud-sql-proxy.linux.amd64 -O cloud-sql-proxy
    - chmod +x cloud-sql-proxy
    
    # Install Node.js for Prisma
    - apk add --no-cache nodejs npm
  script:
    - export CONNECTION_NAME=$(gcloud sql instances describe ${CLOUD_SQL_INSTANCE} --format='value(connectionName)')
    
    # Start Cloud SQL Proxy in background
    - ./cloud-sql-proxy ${CONNECTION_NAME} &
    - sleep 5
    
    # Get database password from secrets
    - export DB_PASSWORD=$(gcloud secrets versions access latest --secret="db-password")
    - export DATABASE_URL="postgresql://postgres:${DB_PASSWORD}@127.0.0.1:5432/${DB_NAME}"
    
    # Run migrations
    - npm ci --prefer-offline
    - npx prisma migrate deploy
    
    - echo "Migrations completed successfully!"
  after_script:
    - rm -f ${HOME}/gcp-key.json
    - pkill -f cloud-sql-proxy || true

# Staging deployment (optional, for testing before production)
deploy:staging:
  stage: deploy
  image: google/cloud-sdk:alpine
  only:
    - develop
  when: manual
  environment:
    name: staging
    url: https://${CLOUD_RUN_SERVICE}-staging-${CI_COMMIT_SHORT_SHA}.run.app
  before_script:
    - echo $GCP_SERVICE_KEY | base64 -d > ${HOME}/gcp-key.json
    - gcloud auth activate-service-account --key-file ${HOME}/gcp-key.json
    - gcloud config set project $GCP_PROJECT_ID
  script:
    - export CONNECTION_NAME=$(gcloud sql instances describe ${CLOUD_SQL_INSTANCE} --format='value(connectionName)')
    
    # Deploy staging with even more aggressive cost settings
    - |
      gcloud run deploy ${CLOUD_RUN_SERVICE}-staging \
        --image ${IMAGE_NAME}:${CI_COMMIT_SHORT_SHA} \
        --platform managed \
        --region ${GCP_REGION} \
        --allow-unauthenticated \
        --set-env-vars "NODE_ENV=staging" \
        --set-secrets "DATABASE_URL=db-url-staging:latest,NEXTAUTH_SECRET=nextauth-secret:latest" \
        --add-cloudsql-instances ${CONNECTION_NAME} \
        --vpc-connector budget-connector \
        --vpc-egress private-ranges-only \
        --min-instances 0 \
        --max-instances 2 \
        --memory 256Mi \
        --cpu 1 \
        --timeout 60 \
        --concurrency 80 \
        --cpu-throttling \
        --port 8080 \
        --quiet
    
    - export SERVICE_URL=$(gcloud run services describe ${CLOUD_RUN_SERVICE}-staging --region ${GCP_REGION} --format='value(status.url)')
    - echo "Staging deployed: ${SERVICE_URL}"
  after_script:
    - rm -f ${HOME}/gcp-key.json

# Health check after deployment
health_check:
  stage: post-deploy
  image: alpine:latest
  only:
    - main
  needs:
    - deploy:production
  before_script:
    - apk add --no-cache curl jq
  script:
    - echo "Waiting for service to be ready..."
    - sleep 10
    
    # Get service URL
    - echo $GCP_SERVICE_KEY | base64 -d > ${HOME}/gcp-key.json
    - apk add --no-cache python3 py3-pip
    - pip3 install --break-system-packages gcloud
    
    - export SERVICE_URL=$(gcloud run services describe ${CLOUD_RUN_SERVICE} --region ${GCP_REGION} --format='value(status.url)' 2>/dev/null || echo "https://${CLOUD_RUN_SERVICE}.run.app")
    
    # Basic health check
    - |
      response=$(curl -s -o /dev/null -w "%{http_code}" ${SERVICE_URL}/ || echo "000")
      if [ "$response" = "200" ] || [ "$response" = "301" ] || [ "$response" = "302" ]; then
        echo "✅ Health check passed! Status: $response"
      else
        echo "❌ Health check failed! Status: $response"
        exit 1
      fi
  after_script:
    - rm -f ${HOME}/gcp-key.json
  allow_failure: true
